%-------------------------------VisionTasker---------------------------

@inproceedings{varghese2024yolov8,
  title={YOLOv8: A Novel Object Detection Algorithm with Enhanced Performance and Robustness},
  author={Varghese, Rejin and Sambath, M},
  booktitle={2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@article{du2020pp,
  title={Pp-ocr: A practical ultra lightweight ocr system},
  author={Du, Yuning and Li, Chenxia and Guo, Ruoyu and Yin, Xiaoting and Liu, Weiwei and Zhou, Jun and Bai, Yifan and Yu, Zilin and Yang, Yehua and Dang, Qingqing and others},
  journal={arXiv preprint arXiv:2009.09941},
  year={2020}
}
%-------------------------------MLLM---------------------------

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{Qwen-VL,
  title={Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}


%-------------------------------scaling law---------------------------
@article{hagendorff2023machine,
  title={Machine psychology: Investigating emergent capabilities and behavior in large language models using psychological methods},
  author={Hagendorff, Thilo},
  journal={arXiv preprint arXiv:2303.13988},
  volume={1},
  year={2023}
}
@article{muennighoff2023scaling,
  title={Scaling data-constrained language models},
  author={Muennighoff, Niklas and Rush, Alexander and Barak, Boaz and Le Scao, Teven and Tazi, Nouamane and Piktus, Aleksandra and Pyysalo, Sampo and Wolf, Thomas and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={50358--50376},
  year={2023}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}


@article{chen2024far,
title={How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites},
author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
journal={arXiv preprint arXiv:2404.16821},
year={2024}
}

@inproceedings{chen2024internvl,
title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages={24185--24198},
year={2024}
}



%-------------------------------mult agent survey---------------------------
@article{chen2019control,
  title={On the control of multi-agent systems: A survey},
  author={Chen, Fei and Ren, Wei and others},
  journal={Foundations and Trends{\textregistered} in Systems and Control},
  volume={6},
  number={4},
  pages={339--499},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{torreno2017cooperative,
  title={Cooperative multi-agent planning: A survey},
  author={Torreno, Alejandro and Onaindia, Eva and Komenda, Anton{\'\i}n and {\v{S}}tolba, Michal},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={6},
  pages={1--32},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{dorri2018multi,
  title={Multi-agent systems: A survey},
  author={Dorri, Ali and Kanhere, Salil S and Jurdak, Raja},
  journal={Ieee Access},
  volume={6},
  pages={28573--28593},
  year={2018},
  publisher={IEEE}
}
@article{li2024survey,
  title={A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges},
  author={Li, Xinyi and Wang, Sai and Zeng, Siqi and Wu, Yu and Yang, Yi},
  journal={Vicinagearth},
  volume={1},
  number={1},
  pages={9},
  year={2024},
  publisher={Springer}
}

%-------------------------------action 执行相关工具---------------------------
@inproceedings{patil2016enhanced,
  title={Enhanced UI Automator Viewer with improved Android accessibility evaluation features},
  author={Patil, Neha and Bhole, Dhananjay and Shete, Prasanna},
  booktitle={2016 International Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)},
  pages={977--983},
  year={2016},
  organization={IEEE}
}

@incollection{lodi2021xctest,
  title={XCTest Introduction},
  author={Lodi, Gio},
  booktitle={Test-Driven Development in Swift: Compile Better Code with XCTest and TDD},
  pages={13--25},
  year={2021},
  publisher={Springer}
}

@article{singh2014automated,
  title={Automated testing of mobile applications using scripting technique: A study on appium},
  author={Singh, Shiwangi and Gadgil, Rucha and Chudgor, Ayushi},
  journal={International Journal of Current Engineering and Technology (IJCET)},
  volume={4},
  number={5},
  pages={3627--3630},
  year={2014}
}

@article{sinclairrole,
  title={The Role of Selenium in Mobile Application Testing},
  author={Sinclair, Chloe}
}
@book{gundecha2015selenium,
  title={Selenium Testing Tools Cookbook},
  author={Gundecha, Unmesh},
  year={2015},
  publisher={Packt Publishing Ltd}
}

%-------------------------------reflection定义---------------------------

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

%-------------------------------reasoning定义---------------------------

@article{plaat2024reasoning,
  title={Reasoning with large language models, a survey},
  author={Plaat, Aske and Wong, Annie and Verberne, Suzan and Broekens, Joost and van Stein, Niki and Back, Thomas},
  journal={arXiv preprint arXiv:2407.11511},
  year={2024}
}

@article{chen2024optimizing,
  title={Optimizing reasoning abilities in large language models: A step-by-step approach},
  author={Chen, Zhiyuan and Li, Yaning and Wang, Kairui},
  journal={Authorea Preprints},
  year={2024},
  publisher={Authorea}
}

@article{gandhi2024understanding,
  title={Understanding social reasoning in language models with language models},
  author={Gandhi, Kanishk and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

%-------------------------------SoM定义---------------------------
@misc{yang2023setofmark,
   title = {Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V},
   url = {https://arxiv.org/abs/2310.11441},
   author={Jianwei Yang and Hao Zhang and Feng Li and Xueyan Zou and Chunyuan Li and Jianfeng Gao},
   eprint={2310.11441},
   year = {2023},
   archivePrefix={arXiv},
   primaryClass={cs.CV}
}

%-------------------------------UI Tree定义---------------------------
@inproceedings{medhi2013comparison,
  title={A comparison of list vs. hierarchical UIs on mobile phones for non-literate users},
  author={Medhi, Indrani and Toyama, Kentaro and Joshi, Anirudha and Athavankar, Uday and Cutrell, Edward},
  booktitle={Human-Computer Interaction--INTERACT 2013: 14th IFIP TC 13 International Conference, Cape Town, South Africa, September 2-6, 2013, Proceedings, Part II 14},
  pages={497--504},
  year={2013},
  organization={Springer}
}

@article{rasanen2015sequence,
  title={Sequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns},
  author={R{\"a}s{\"a}nen, Okko J and Saarinen, Jukka P},
  journal={IEEE transactions on neural networks and learning systems},
  volume={27},
  number={9},
  pages={1878--1889},
  year={2015},
  publisher={IEEE}
}

%-------------------------------POMDP---------------------------
@article{monahan1982state,
  title={State of the art—a survey of partially observable Markov decision processes: theory, models, and algorithms},
  author={Monahan, George E},
  journal={Management science},
  volume={28},
  number={1},
  pages={1--16},
  year={1982},
  publisher={INFORMS}
}

@incollection{spaan2012partially,
  title={Partially observable Markov decision processes},
  author={Spaan, Matthijs TJ},
  booktitle={Reinforcement learning: State-of-the-art},
  pages={387--414},
  year={2012},
  publisher={Springer}
}
%-------------------------------llm contextual---------------------------
@article{talukdar2024improving,
  title={Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity},
  author={Talukdar, Wrick and Biswas, Anjanava},
  journal={arXiv preprint arXiv:2408.04023},
  year={2024}
}

@inproceedings{koike2024outfox,
  title={Outfox: Llm-generated essay detection through in-context learning with adversarially generated examples},
  author={Koike, Ryuto and Kaneko, Masahiro and Okazaki, Naoaki},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21258--21266},
  year={2024}
}

%-------------------------------llm reasonning---------------------------
@article{wang2023can,
  title={Can ChatGPT defend its belief in truth? evaluating LLM reasoning via debate},
  author={Wang, Boshi and Yue, Xiang and Sun, Huan},
  journal={arXiv preprint arXiv:2305.13160},
  year={2023}
}

@article{yuan2024advancing,
  title={Advancing llm reasoning generalists with preference trees},
  author={Yuan, Lifan and Cui, Ganqu and Wang, Hanbin and Ding, Ning and Wang, Xingyao and Deng, Jia and Shan, Boji and Chen, Huimin and Xie, Ruobing and Lin, Yankai and others},
  journal={arXiv preprint arXiv:2404.02078},
  year={2024}
}

%-------------------------------llm planning---------------------------
@inproceedings{song2023llm,
  title={Llm-planner: Few-shot grounded planning for embodied agents with large language models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3009},
  year={2023}
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={75993--76005},
  year={2023}
}
%-------------------------------llm Survey---------------------------
@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{minaee2024large,
  title={Large language models: A survey},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024}
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}
%-------------------------------UI 元素复杂---------------------------
@article{brich2017exploring,
  title={Exploring end user programming needs in home automation},
  author={Brich, Julia and Walch, Marcel and Rietzler, Michael and Weber, Michael and Schaub, Florian},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={24},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}


%-------------------------------基于规则的意图理解---------------------------
@article{kang2013using,
  title={Using rule-based natural language processing to improve disease normalization in biomedical text},
  author={Kang, Ning and Singh, Bharat and Afzal, Zubair and van Mulligen, Erik M and Kors, Jan A},
  journal={Journal of the American Medical Informatics Association},
  volume={20},
  number={5},
  pages={876--881},
  year={2013},
  publisher={BMJ Publishing Group}
}

@inproceedings{anicic2010rule,
  title={A rule-based language for complex event processing and reasoning},
  author={Anicic, Darko and Fodor, Paul and Rudolph, Sebastian and St{\"u}hmer, Roland and Stojanovic, Nenad and Studer, Rudi},
  booktitle={Web Reasoning and Rule Systems: Fourth International Conference, RR 2010, Bressanone/Brixen, Italy, September 22-24, 2010. Proceedings 4},
  pages={42--57},
  year={2010},
  organization={Springer}
}

@inproceedings{karanikolas2023large,
  title={Large language models versus natural language understanding and generation},
  author={Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael},
  booktitle={Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
  pages={278--290},
  year={2023}
}

%-------------------------------shortcut门槛高---------------------------
@article{le2020shortcut,
  title={Shortcut gestures for mobile text editing on fully touch sensitive smartphones},
  author={Le, Huy Viet and Mayer, Sven and Wei{\ss}, Maximilian and Vogelsang, Jonas and Weing{\"a}rtner, Henrike and Henze, Niels},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={27},
  number={5},
  pages={1--38},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{roffarello2024trigger,
  title={Trigger-Action Programming for Wellbeing: Insights From 6590 iOS Shortcuts},
  author={Roffarello, Alberto Monge and Purohit, Aditya Kumar and Purohit, Satyam V},
  journal={IEEE Pervasive Computing},
  year={2024},
  publisher={IEEE}
}

%-------------------------------RPA 脚本频繁替换---------------------------

@article{agostinelli2022reactive,
  title={Reactive synthesis of software robots in RPA from user interface logs},
  author={Agostinelli, Simone and Lupia, Marco and Marrella, Andrea and Mecella, Massimo},
  journal={Computers in Industry},
  volume={142},
  pages={103721},
  year={2022},
  publisher={Elsevier}
}

@book{tripathi2018learning,
  title={Learning Robotic Process Automation: Create Software robots and automate business processes with the leading RPA tool--UiPath},
  author={Tripathi, Alok Mani},
  year={2018},
  publisher={Packt Publishing Ltd}
}

@inproceedings{ling2020intelligent,
  title={Intelligent document processing based on RPA and machine learning},
  author={Ling, Xufeng and Gao, Ming and Wang, Dong},
  booktitle={2020 Chinese Automation Congress (CAC)},
  pages={1349--1353},
  year={2020},
  organization={IEEE}
}

%-------------------------------泛化性挑战---------------------------
@article{liu2023understanding,
  title={Understanding In-Situ Programming for Smart Home Automation},
  author={Liu, Xiaoyi and Shi, Yingtian and Yu, Chun and Gao, Cheng and Yang, Tianao and Liang, Chen and Shi, Yuanchun},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={7},
  number={2},
  pages={1--31},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{majeed2020intelligent,
  title={An intelligent, secure, and smart home automation system},
  author={Majeed, Rizwan and Abdullah, Nurul Azma and Ashraf, Imran and Zikria, Yousaf Bin and Mushtaq, Muhammad Faheem and Umer, Muhammad},
  journal={Scientific Programming},
  volume={2020},
  number={1},
  pages={4579291},
  year={2020},
  publisher={Wiley Online Library}
}

%-------------------------------shortcuts---------------------------
@inproceedings{bridle2006inducing,
  title={Inducing shortcuts on a mobile phone interface},
  author={Bridle, Robert and McCreath, Eric},
  booktitle={Proceedings of the 11th international conference on Intelligent user interfaces},
  pages={327--329},
  year={2006}
}

@inproceedings{guerreiro2008mnemonical,
  title={Mnemonical body shortcuts: improving mobile interaction},
  author={Guerreiro, Tiago and Gamboa, Ricardo and Jorge, Joaquim},
  booktitle={Proceedings of the 15th European conference on Cognitive ergonomics: the ergonomics of cool interaction},
  pages={1--8},
  year={2008}
}

@article{kennedy2011use,
  title={Use of cognitive shortcuts in landline and cell phone surveys},
  author={Kennedy, Courtney and Everett, Stephen E},
  journal={Public Opinion Quarterly},
  volume={75},
  number={2},
  pages={336--348},
  year={2011},
  publisher={Oxford University Press}
}

%-------------------------------RPA 挑战---------------------------
@article{syed2020robotic,
  title={Robotic process automation: contemporary themes and challenges},
  author={Syed, Rehan and Suriadi, Suriadi and Adams, Michael and Bandara, Wasana and Leemans, Sander JJ and Ouyang, Chun and Ter Hofstede, Arthur HM and Van De Weerd, Inge and Wynn, Moe Thandar and Reijers, Hajo A},
  journal={Computers in Industry},
  volume={115},
  pages={103162},
  year={2020},
  publisher={Elsevier}
}

@article{pramod2022robotic,
  title={Robotic process automation for industry: adoption status, benefits, challenges and research agenda},
  author={Pramod, Dhanya},
  journal={Benchmarking: an international journal},
  volume={29},
  number={5},
  pages={1562--1586},
  year={2022},
  publisher={Emerald Publishing Limited}
}

%----------------------GUI 序列生成------------------------------------
@inproceedings{jensen2013automated,
  title={Automated testing with targeted event sequence generation},
  author={Jensen, Casper S and Prasad, Mukul R and M{\o}ller, Anders},
  booktitle={Proceedings of the 2013 International Symposium on Software Testing and Analysis},
  pages={67--77},
  year={2013}
}
%----------------------APP 复杂多样------------------------------------
@inproceedings{hecht2015tracking,
  title={Tracking the software quality of android applications along their evolution (t)},
  author={Hecht, Geoffrey and Benomar, Omar and Rouvoy, Romain and Moha, Naouel and Duchien, Laurence},
  booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages={236--247},
  year={2015},
  organization={IEEE}
}

%----------------------DQN------------------------------------
@inproceedings{fan2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
  booktitle={Learning for dynamics and control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

%----------------------RL Survey------------------------------------
@article{ladosz2022exploration,
  title={Exploration in deep reinforcement learning: A survey},
  author={Ladosz, Pawel and Weng, Lilian and Kim, Minwoo and Oh, Hyondong},
  journal={Information Fusion},
  volume={85},
  pages={1--22},
  year={2022},
  publisher={Elsevier}
}

@article{luo2024survey,
  title={A survey on model-based reinforcement learning},
  author={Luo, Fan-Ming and Xu, Tian and Lai, Hang and Chen, Xiong-Hui and Zhang, Weinan and Yu, Yang},
  journal={Science China Information Sciences},
  volume={67},
  number={2},
  pages={121101},
  year={2024},
  publisher={Springer}
}

%----------------------embodied AI Survey------------------------------------
@article{duan2022survey,
  title={A survey of embodied ai: From simulators to research tasks},
  author={Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={6},
  number={2},
  pages={230--244},
  year={2022},
  publisher={IEEE}
}

@article{pfeifer2004embodied,
  title={Embodied artificial intelligence: Trends and challenges},
  author={Pfeifer, Rolf and Iida, Fumiya},
  journal={Lecture notes in computer science},
  pages={1--26},
  year={2004},
  publisher={Springer}
}

%----------------------AGI Survey------------------------------------
@article{goertzel2014artificial,
  title={Artificial general intelligence: concept, state of the art, and future prospects},
  author={Goertzel, Ben},
  journal={Journal of Artificial General Intelligence},
  volume={5},
  number={1},
  pages={1},
  year={2014},
  publisher={De Gruyter Poland}
}

%----------------------ai agents without llm challenge------------------------------------
@inproceedings{luger2016like,
  title={" Like Having a Really Bad PA" The Gulf between User Expectation and Experience of Conversational Agents},
  author={Luger, Ewa and Sellen, Abigail},
  booktitle={Proceedings of the 2016 CHI conference on human factors in computing systems},
  pages={5286--5297},
  year={2016}
}

@article{amershi2014power,
  title={Power to the people: The role of humans in interactive machine learning},
  author={Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  journal={AI magazine},
  volume={35},
  number={4},
  pages={105--120},
  year={2014}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{kohl2019mode,
  title={Mode of action of microbial biological control agents against plant diseases: relevance beyond efficacy},
  author={K{\"o}hl, J{\"u}rgen and Kolnaar, Rogier and Ravensberg, Willem J},
  journal={Frontiers in plant science},
  volume={10},
  pages={845},
  year={2019},
  publisher={Frontiers Media SA}
}

%----------------------ai agents without llm------------------------------------
@book{poole2010artificial,
  title={Artificial Intelligence: foundations of computational agents},
  author={Poole, David L and Mackworth, Alan K},
  year={2010},
  publisher={Cambridge University Press}
}

@article{inkster2018empathy,
  title={An empathy-driven, conversational artificial intelligence agent (Wysa) for digital mental well-being: real-world data evaluation mixed-methods study},
  author={Inkster, Becky and Sarda, Shubhankar and Subramanian, Vinod and others},
  journal={JMIR mHealth and uHealth},
  volume={6},
  number={11},
  pages={e12106},
  year={2018},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@inproceedings{gao2018neural,
  title={Neural approaches to conversational AI},
  author={Gao, Jianfeng and Galley, Michel and Li, Lihong},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={1371--1374},
  year={2018}
}

%----------------------传统 agent------------------------------------
@misc{anscombe2000intention,
  title={Intention},
  author={Anscombe, GEM},
  year={2000},
  publisher={Harvard University Press}
}

@article{dennett1988precis,
  title={Pr{\'e}cis of the intentional stance},
  author={Dennett, Daniel C},
  journal={Behavioral and brain sciences},
  volume={11},
  number={3},
  pages={495--505},
  year={1988},
  publisher={Cambridge University Press}
}

@article{shoham1993agent,
  title={Agent-oriented programming},
  author={Shoham, Yoav},
  journal={Artificial intelligence},
  volume={60},
  number={1},
  pages={51--92},
  year={1993},
  publisher={Elsevier}
}

%----------------------构建具备规划决策能力的自主智能体是AI的长远目标------------------------------------
@article{albrecht2018autonomous,
  title={Autonomous agents modelling other agents: A comprehensive survey and open problems},
  author={Albrecht, Stefano V and Stone, Peter},
  journal={Artificial Intelligence},
  volume={258},
  pages={66--95},
  year={2018},
  publisher={Elsevier}
}

%----------------------llm agent survey------------------------------------
@article{li2024personal,
  title={Personal llm agents: Insights and survey about the capability, efficiency and security},
  author={Li, Yuanchun and Wen, Hao and Wang, Weijun and Li, Xiangyu and Yuan, Yizhen and Liu, Guohong and Liu, Jiacheng and Xu, Wenxing and Wang, Xiang and Sun, Yi and others},
  journal={arXiv preprint arXiv:2401.05459},
  year={2024}
}

@article{huang2024understanding,
  title={Understanding the planning of LLM agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@article{guo2024large,
  title={Large language model based multi-agents: A survey of progress and challenges},
  author={Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  journal={arXiv preprint arXiv:2402.01680},
  year={2024}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}

@article{jin2024llms,
  title={From llms to llm-based agents for software engineering: A survey of current, challenges and future},
  author={Jin, Haolin and Huang, Linghan and Cai, Haipeng and Yan, Jun and Li, Bo and Chen, Huaming},
  journal={arXiv preprint arXiv:2408.02479},
  year={2024}
}

%----------------------大模型自然语言处理------------------------------------
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

%----------------------GUI理解文献------------------------------------
@article{fu2024understanding,
  title={Understanding mobile GUI: From pixel-words to screen-sentences},
  author={Fu, Jingwen and Zhang, Xiaoyi and Wang, Yuwang and Zeng, Wenjun and Zheng, Nanning},
  journal={Neurocomputing},
  volume={601},
  pages={128200},
  year={2024},
  publisher={Elsevier}
}

@article{banerjee2013graphical,
  title={Graphical user interface (GUI) testing: Systematic mapping and repository},
  author={Banerjee, Ishan and Nguyen, Bao and Garousi, Vahid and Memon, Atif},
  journal={Information and Software Technology},
  volume={55},
  number={10},
  pages={1679--1694},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{chen2018ui,
  title={From ui design image to gui skeleton: a neural machine translator to bootstrap mobile gui implementation},
  author={Chen, Chunyang and Su, Ting and Meng, Guozhu and Xing, Zhenchang and Liu, Yang},
  booktitle={Proceedings of the 40th International Conference on Software Engineering},
  pages={665--676},
  year={2018}
}
%----------------------传统手机助手文献------------------------------------
@inproceedings{kepuska2018next,
  title={Next-generation of virtual personal assistants (microsoft cortana, apple siri, amazon alexa and google home)},
  author={Kepuska, Veton and Bohouta, Gamal},
  booktitle={2018 IEEE 8th annual computing and communication workshop and conference (CCWC)},
  pages={99--103},
  year={2018},
  organization={IEEE}
}

@inproceedings{cowan2017can,
  title={" What can i help you with?" infrequent users' experiences of intelligent personal assistants},
  author={Cowan, Benjamin R and Pantidi, Nadia and Coyle, David and Morrissey, Kellie and Clarke, Peter and Al-Shehri, Sara and Earley, David and Bandeira, Natasha},
  booktitle={Proceedings of the 19th international conference on human-computer interaction with mobile devices and services},
  pages={1--12},
  year={2017}
}

%----------------------成本高的挑战------------------------------------
@inproceedings{kodali2019low,
  title={Low cost smart home automation system using smart phone},
  author={Kodali, Ravi Kishore and Rajanarayanan, Sasweth C and Boppana, Lakshmi and Sharma, Samradh and Kumar, Ankit},
  booktitle={2019 IEEE R10 humanitarian technology conference (R10-HTC)(47129)},
  pages={120--125},
  year={2019},
  organization={IEEE}
}

@inproceedings{kodali2017low,
  title={Low cost implementation of smart home automation},
  author={Kodali, Ravi Kishore and Mahesh, Kopulwar Shishir},
  booktitle={2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
  pages={461--466},
  year={2017},
  organization={IEEE}
}

@article{moreira2023process,
  title={Process automation using RPA--a literature review},
  author={Moreira, S{\'\i}lvia and Mamede, Henrique S and Santos, Arnaldo},
  journal={Procedia Computer Science},
  volume={219},
  pages={244--254},
  year={2023},
  publisher={Elsevier}
}

@article{lamberton2017impact,
  title={Impact of Robotics, RPA and AI on the insurance industry: challenges and opportunities},
  author={Lamberton, Chris and Brigo, Damiano and Hoy, Dave},
  journal={Journal of Financial Perspectives},
  volume={4},
  number={1},
  year={2017}
}

@article{meironke2022measure,
  title={How to Measure RPA's Benefits? A Review on Metrics, Indicators, and Evaluation Methods of RPA Benefit Assessment},
  author={Meironke, Anja and Kuehnel, Stephan},
  year={2022}
}
%----------------------通用性挑战------------------------------------
@article{clarke2016therapeutic,
  title={Therapeutic alliance with a fully automated mobile phone and web-based intervention: secondary analysis of a randomized controlled trial},
  author={Clarke, Janine and Proudfoot, Judith and Whitton, Alexis and Birch, Mary-Rose and Boyd, Megan and Parker, Gordon and Manicavasagar, Vijaya and Hadzi-Pavlovic, Dusan and Fogarty, Andrea and others},
  journal={JMIR mental health},
  volume={3},
  number={1},
  pages={e4656},
  year={2016},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@inproceedings{li2017sugilite,
  title={SUGILITE: creating multimodal smartphone automation by demonstration},
  author={Li, Toby Jia-Jun and Azaria, Amos and Myers, Brad A},
  booktitle={Proceedings of the 2017 CHI conference on human factors in computing systems},
  pages={6038--6049},
  year={2017}
}

@article{patel2015home,
  title={Home automation system (HAS) using android for mobile phone},
  author={Patel, Syeh Mujeeb and Pasha, Syed Jilani},
  journal={International Journal Of Scientific Engeneering and Technology Research,, ISSN},
  pages={2319--8885},
  year={2015}
}

@inproceedings{asadullah2016overview,
  title={An overview of home automation systems},
  author={Asadullah, Muhammad and Raza, Ahsan},
  booktitle={2016 2nd international conference on robotics and artificial intelligence (ICRAI)},
  pages={27--31},
  year={2016},
  organization={IEEE}
}
%----------------------手机app自动测试综述------------------------------------
@inproceedings{kirubakaran2013mobile,
  title={Mobile application testing—Challenges and solution approach through automation},
  author={Kirubakaran, B and Karthikeyani, V},
  booktitle={2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering},
  pages={79--84},
  year={2013},
  organization={IEEE}
}

@article{kong2018automated,
  title={Automated testing of android apps: A systematic literature review},
  author={Kong, Pingfan and Li, Li and Gao, Jun and Liu, Kui and Bissyand{\'e}, Tegawend{\'e} F and Klein, Jacques},
  journal={IEEE Transactions on Reliability},
  volume={68},
  number={1},
  pages={45--66},
  year={2018},
  publisher={IEEE}
}

@inproceedings{linares2017continuous,
  title={Continuous, evolutionary and large-scale: A new perspective for automated mobile app testing},
  author={Linares-V{\'a}squez, Mario and Moran, Kevin and Poshyvanyk, Denys},
  booktitle={2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  pages={399--410},
  year={2017},
  organization={IEEE}
}

@article{zein2016systematic,
  title={A systematic mapping study of mobile application testing techniques},
  author={Zein, Samer and Salleh, Norsaremah and Grundy, John},
  journal={Journal of Systems and Software},
  volume={117},
  pages={334--356},
  year={2016},
  publisher={Elsevier}
}

%----------------------相关综述------------------------------------
@article{wu2024foundations,
  title={Foundations and recent trends in multimodal mobile agents: A survey},
  author={Wu, Biao and Li, Yanda and Fang, Meng and Song, Zirui and Zhang, Zhiwei and Wei, Yunchao and Chen, Ling},
  journal={arXiv preprint arXiv:2411.02006},
  year={2024}
}

@article{wang2024gui,
  title={GUI Agents with Foundation Models: A Comprehensive Survey},
  author={Wang, Shuai and Liu, Weiwen and Chen, Jingxuan and Gan, Weinan and Zeng, Xingshan and Yu, Shuai and Hao, Xinlong and Shao, Kun and Wang, Yasheng and Tang, Ruiming},
  journal={arXiv preprint arXiv:2411.04890},
  year={2024}
}

@article{zhang2024large,
  title={Large Language Model-Brained GUI Agents: A Survey},
  author={Zhang, Chaoyun and He, Shilin and Qian, Jiaxu and Li, Bowen and Li, Liqun and Qin, Si and Kang, Yu and Ma, Minghua and Lin, Qingwei and Rajmohan, Saravan and others},
  journal={arXiv preprint arXiv:2411.18279},
  year={2024}
}

%----------------------plan then act------------------------------------
@article{hoscilowicz2024clickagent,
  title={ClickAgent: Enhancing UI Location Capabilities of Autonomous Agents},
  author={Hoscilowicz, Jakub and Maj, Bartosz and Kozakiewicz, Bartosz and Tymoshchuk, Oleksii and Janicki, Artur},
  journal={arXiv preprint arXiv:2410.11872},
  year={2024}
}

@article{christianos2024lightweight,
  title={Lightweight Neural App Control},
  author={Christianos, Filippos and Papoudakis, Georgios and Coste, Thomas and Hao, Jianye and Wang, Jun and Shao, Kun},
  journal={arXiv preprint arXiv:2410.17883},
  year={2024}
}

%----------------------benchmark------------------------------------
@article{zhang2023mobileenv,
  title={Mobile-env: A universal platform for training and evaluation of mobile interaction},
  author={Zhang, Danyang and Chen, Lu and Yu, Kai},
  journal={arXiv preprint arXiv:2305.08144},
  year={2023}
}

@article{lee2024BMoCA,
  title={Benchmarking Mobile Device Control Agents across Diverse Configurations},
  author={Lee, Juyong and Min, Taywon and An, Minyong and Hahm, Dongyoon and Lee, Haeone and Kim, Changyeon and Lee, Kimin},
  journal={arXiv preprint arXiv:2404.16660},
  year={2024}
}

@article{xu2024androidlab,
  title={AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents},
  author={Xu, Yifan and Liu, Xiao and Sun, Xueqiao and Cheng, Siyi and Yu, Hao and Lai, Hanyu and Zhang, Shudan and Zhang, Dan and Tang, Jie and Dong, Yuxiao},
  journal={arXiv preprint arXiv:2410.24024},
  year={2024}
}

%----------------------数据集------------------------------------
@article{li2020PixelHelp,
  title={Mapping natural language instructions to mobile UI action sequences},
  author={Li, Yang and He, Jiacong and Zhou, Xin and Zhang, Yuan and Baldridge, Jason},
  journal={arXiv preprint arXiv:2005.03776},
  year={2020}
}

@article{burns2021motif,
  title={Mobile app tasks with iterative feedback (motif): Addressing task feasibility in interactive visual environments},
  author={Burns, Andrea and Arsan, Deniz and Agrawal, Sanjna and Kumar, Ranjitha and Saenko, Kate and Plummer, Bryan A},
  journal={arXiv preprint arXiv:2104.08560},
  year={2021}
}

@article{bai2021uibert,
  title={Uibert: Learning generic multimodal representations for ui understanding},
  author={Bai, Chongyang and Zang, Xiaoxue and Xu, Ying and Sunkara, Srinivas and Rastogi, Abhinav and Chen, Jindong and others},
  journal={arXiv preprint arXiv:2107.13731},
  year={2021}
}

@article{sun2022metagui,
  title={Meta-gui: Towards multi-modal conversational agents on mobile gui},
  author={Sun, Liangtai and Chen, Xingyu and Chen, Lu and Dai, Tianle and Zhu, Zichen and Yu, Kai},
  journal={arXiv preprint arXiv:2205.11029},
  year={2022}
}

@article{venkatesh2022ugif,
  title={Ugif: Ui grounded instruction following},
  author={Venkatesh, Sagar Gubbi and Talukdar, Partha and Narayanan, Srini},
  journal={arXiv preprint arXiv:2211.07615},
  year={2022}
}
%----------------------RL------------------------------------
@article{liu2024autoglm,
  title={AutoGLM: Autonomous Foundation Agents for GUIs},
  author={Liu, Xiao and Qin, Bo and Liang, Dongzhu and Dong, Guang and Lai, Hanyu and Zhang, Hanchen and Zhao, Hanlin and Iong, Iat Long and Sun, Jiadai and Wang, Jiaqi and others},
  journal={arXiv preprint arXiv:2411.00820},
  year={2024}
}

@article{putta2024agentq,
  title={Agent q: Advanced reasoning and learning for autonomous ai agents},
  author={Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
  journal={arXiv preprint arXiv:2408.07199},
  year={2024}
}

%----------------------prompt  engineering------------------------------------

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}
%----------------------single agent------------------------------------
@inproceedings{wang2023enabling,
  title={Enabling conversational interaction with mobile ui using large language models},
  author={Wang, Bryan and Li, Gang and Li, Yang},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

%----------------------商业化应用------------------------------------

@misc{apple_intelligence,
  author       = {Apple Inc.},
  title        = {Apple Intelligence},
  year         = {2024}, 
  url          = {https://www.apple.com/apple-intelligence/}, 
  note         = {Accessed: 2024-11-28}
}

@misc{google_assistant_support,
  author       = {Google LLC},
  title        = {Google Assistant Support},
  year         = {2024}, 
  url          = {https://support.google.com/assistant/}, 
  note         = {Accessed: 2024-11-28}
}

@misc{honor_magicos,
  author       = {Honor},
  title        = {Honor MagicOS 9.0},
  year         = {2024}, 
  url          = {https://www.honor.com/cn/magic-os/}, 
  note         = {Accessed: 2024-11-28}
}
%----------------------Advancing Phone Automation with LLMs------------------------------------

%GPT系列的论文
@article{radford2018gpt1,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{radford2019gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
%----------------------ule-Based Automation and Shortcuts------------------------------------

@inproceedings{agostinelli2019research,
  title={Research challenges for intelligent robotic process automation},
  author={Agostinelli, Simone and Marrella, Andrea and Mecella, Massimo},
  booktitle={Business Process Management Workshops: BPM 2019 International Workshops, Vienna, Austria, September 1--6, 2019, Revised Selected Papers 17},
  pages={12--18},
  year={2019},
  organization={Springer}
}
%----------------------Phone Automation Testing------------------------------------
@article{zhao2024dinodroid,
  title={Dinodroid: Testing android apps using deep q-networks},
  author={Zhao, Yu and Harrison, Brent and Yu, Tingting},
  journal={ACM Transactions on Software Engineering and Methodology},
  volume={33},
  number={5},
  pages={1--24},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{machiry2013dynodroid,
  title={Dynodroid: An input generation system for android apps},
  author={Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
  booktitle={Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  pages={224--234},
  year={2013}
}

@inproceedings{amalfitano2012using,
  title={Using GUI ripping for automated testing of Android applications},
  author={Amalfitano, Domenico and Fasolino, Anna Rita and Tramontana, Porfirio and De Carmine, Salvatore and Memon, Atif M},
  booktitle={Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
  pages={258--261},
  year={2012}
}

@article{amalfitano2014mobiguitar,
  title={MobiGUITAR: Automated model-based testing of mobile apps},
  author={Amalfitano, Domenico and Fasolino, Anna Rita and Tramontana, Porfirio and Ta, Bryan Dzung and Memon, Atif M},
  journal={IEEE software},
  volume={32},
  number={5},
  pages={53--59},
  year={2014},
  publisher={IEEE}
}

@inproceedings{azim2013targeted,
  title={Targeted and depth-first exploration for systematic testing of android apps},
  author={Azim, Tanzirul and Neamtiu, Iulian},
  booktitle={Proceedings of the 2013 ACM SIGPLAN international conference on Object oriented programming systems languages \& applications},
  pages={641--660},
  year={2013}
}

@inproceedings{pan2020reinforcement,
  title={Reinforcement learning based curiosity-driven testing of Android applications},
  author={Pan, Minxue and Huang, An and Wang, Guoxin and Zhang, Tian and Li, Xuandong},
  booktitle={Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages={153--164},
  year={2020}
}

@inproceedings{koroglu2018qbe,
  title={Qbe: Qlearning-based exploration of android applications},
  author={Koroglu, Yavuz and Sen, Alper and Muslu, Ozlem and Mete, Yunus and Ulker, Ceyda and Tanriverdi, Tolga and Donmez, Yunus},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)},
  pages={105--115},
  year={2018},
  organization={IEEE}
}

@inproceedings{li2019humanoid,
  title={Humanoid: A deep learning-based approach to automated black-box android app testing},
  author={Li, Yuanchun and Yang, Ziyue and Guo, Yao and Chen, Xiangqun},
  booktitle={2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  pages={1070--1073},
  year={2019},
  organization={IEEE}
}

@inproceedings{degott2019learning,
  title={Learning user interface element interactions},
  author={Degott, Christian and Borges Jr, Nataniel P and Zeller, Andreas},
  booktitle={Proceedings of the 28th ACM SIGSOFT international symposium on software testing and analysis},
  pages={296--306},
  year={2019}
}

%----------------------谷歌应用商店的应用数量------------------------------------
@article{nass2021many,
  title={Why many challenges with GUI test automation (will) remain},
  author={Nass, Michel and Al{\'e}groth, Emil and Feldt, Robert},
  journal={Information and Software Technology},
  volume={138},
  pages={106625},
  year={2021},
  publisher={Elsevier}
}

@phdthesis{nass2024overcoming,
  title={On overcoming challenges with GUI-based test automation},
  author={Nass, Michel},
  year={2024},
  school={Blekinge Tekniska H{\"o}gskola}
}

@inproceedings{deshmukh2023automated,
  title={Automated GUI Testing for Enhancing User Experience (UX): A Survey of the State of the Art},
  author={Deshmukh, Parth S and Date, Saroj S and Mahalle, Parikshit N and Barot, Janki},
  booktitle={International Conference on ICT for Sustainable Development},
  pages={619--628},
  year={2023},
  organization={Springer}
}

@article{arnatovich2018systematic,
  title={A systematic literature review of automated techniques for functional gui testing of mobile applications},
  author={Arnatovich, Yauhen Leanidavich and Wang, Lipo},
  journal={arXiv preprint arXiv:1812.11470},
  year={2018}
}

@article{tramontana2019automated,
  title={Automated functional testing of mobile applications: a systematic mapping study},
  author={Tramontana, Porfirio and Amalfitano, Domenico and Amatucci, Nicola and Fasolino, Anna Rita},
  journal={Software Quality Journal},
  volume={27},
  pages={149--201},
  year={2019},
  publisher={Springer}
}

%----------------------大模型是AGI的花火------------------------------------
@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

%----------------------最主要参考的agent综述------------------------------------
@article{xi2023rise,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={arXiv preprint arXiv:2309.07864},
  year={2023}
}



%----------------------大模型推动了智能体系统的发展------------------------------------
@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{hong2023metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}

@inproceedings{qian2024chatdev,
  title={Chatdev: Communicative agents for software development},
  author={Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={15174--15186},
  year={2024}
}

@article{li2023camel,
  title={Camel: Communicative agents for" mind" exploration of large language model society},
  author={Li, Guohao and Hammoud, Hasan and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={51991--52008},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{boiko2023emergent,
  title={Emergent autonomous scientific research capabilities of large language models},
  author={Boiko, Daniil A and MacKnight, Robert and Gomes, Gabe},
  journal={arXiv preprint arXiv:2304.05332},
  year={2023}
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  volume={6},
  number={3},
  year={2023}
}

@article{dong2024self,
  title={Self-collaboration code generation via chatgpt},
  author={Dong, Yihong and Jiang, Xue and Jin, Zhi and Li, Ge},
  journal={ACM Transactions on Software Engineering and Methodology},
  volume={33},
  number={7},
  pages={1--38},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{xia2023towards,
  title={Towards autonomous system: flexible modular production system enhanced with large language model agents},
  author={Xia, Yuchen and Shenoy, Manthan and Jazdi, Nasser and Weyrich, Michael},
  booktitle={2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{dasgupta2023collaborating,
  title={Collaborating with language models for embodied reasoning},
  author={Dasgupta, Ishita and Kaeser-Chen, Christine and Marino, Kenneth and Ahuja, Arun and Babayan, Sheila and Hill, Felix and Fergus, Rob},
  journal={arXiv preprint arXiv:2302.00763},
  year={2023}
}

%----------------------appagent paper liast------------------------------------
@article{wen2023droidbot,
  title={Droidbot-gpt: Gpt-powered ui automation for android},
  author={Wen, Hao and Wang, Hongming and Liu, Jiaxuan and Li, Yuanchun},
  journal={arXiv preprint arXiv:2304.07061},
  year={2023}
}

@article{deng2024mind2web,
  title={Mind2web: Towards a generalist agent for the web},
  author={Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Sam and Wang, Boshi and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhang2023youautoui,
  title={You only look at screens: Multimodal chain-of-action agents},
  author={Zhang, Zhuosheng and Zhang, Aston},
  journal={arXiv preprint arXiv:2309.11436},
  year={2023}
}

@inproceedings{wen2024autodroid,
  title={Autodroid: Llm-powered task automation in android},
  author={Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin},
  booktitle={Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
  pages={543--557},
  year={2024}
}

@inproceedings{sodhi2024step,
  title={Step: Stacked llm policies for web actions},
  author={Sodhi, Paloma and Branavan, SRK and Artzi, Yoav and McDonald, Ryan},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@article{yan2023gpt,
  title={Gpt-4v in wonderland: Large multimodal models for zero-shot smartphone gui navigation},
  author={Yan, An and Yang, Zhengyuan and Zhu, Wanrong and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Zhong, Yiwu and McAuley, Julian and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2311.07562},
  year={2023}
}

@inproceedings{hong2024cogagent,
  title={Cogagent: A visual language model for gui agents},
  author={Hong, Wenyi and Wang, Weihan and Lv, Qingsong and Xu, Jiazheng and Yu, Wenmeng and Ji, Junhui and Wang, Yan and Wang, Zihan and Dong, Yuxiao and Ding, Ming and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14281--14290},
  year={2024}
}

@article{song2023navigating,
  title={Navigating Interfaces with AI for Enhanced User Interaction},
  author={Song, Yunpeng and Bian, Yiheng and Tang, Yongtao and Cai, Zhongmin},
  journal={arXiv preprint arXiv:2312.11190},
  year={2023}
}

@article{zhang2023appagent,
  title={Appagent: Multimodal agents as smartphone users},
  author={Zhang, Chi and Yang, Zhao and Liu, Jiaxuan and Han, Yucheng and Chen, Xin and Huang, Zebiao and Fu, Bin and Yu, Gang},
  journal={arXiv preprint arXiv:2312.13771},
  year={2023}
}

@article{lee2023exploremobilegpt,
  title={Explore, select, derive, and recall: Augmenting llm with human-like memory for mobile task automation},
  author={Lee, Sunjae and Choi, Junyoung and Lee, Jungjae and Wasi, Munim Hasan and Choi, Hojun and Ko, Steven Y and Oh, Sangeun and Shin, Insik},
  journal={arXiv preprint arXiv:2312.03003},
  year={2023}
}

@inproceedings{kil2024dual,
  title={Dual-View Visual Contextualization for Web Navigation},
  author={Kil, Jihyung and Song, Chan Hee and Zheng, Boyuan and Deng, Xiang and Su, Yu and Chao, Wei-Lun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14445--14454},
  year={2024}
}

@inproceedings{chen2024webvln,
  title={Webvln: Vision-and-language navigation on websites},
  author={Chen, Qi and Pitawela, Dileepa and Zhao, Chongyang and Zhou, Gengze and Chen, Hsiang-Ting and Wu, Qi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={2},
  pages={1165--1173},
  year={2024}
}

@article{rawles2024androidinthewild,
  title={Androidinthewild: A large-scale dataset for android device control},
  author={Rawles, Christopher and Li, Alice and Rodriguez, Daniel and Riva, Oriana and Lillicrap, Timothy},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2024mobileagentv1,
  title={Mobile-agent: Autonomous multi-modal mobile device agent with visual perception},
  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2401.16158},
  year={2024}
}

@article{cheng2024seeclick,
  title={Seeclick: Harnessing gui grounding for advanced visual gui agents},
  author={Cheng, Kanzhi and Sun, Qiushi and Chu, Yougang and Xu, Fangzhi and Li, Yantao and Zhang, Jianbing and Wu, Zhiyong},
  journal={arXiv preprint arXiv:2401.10935},
  year={2024}
}

@article{zheng2024gpt,
  title={Gpt-4v (ision) is a generalist web agent, if grounded},
  author={Zheng, Boyuan and Gou, Boyu and Kil, Jihyung and Sun, Huan and Su, Yu},
  journal={arXiv preprint arXiv:2401.01614},
  year={2024}
}

@article{niu2024screenagent,
  title={Screenagent: A vision language model-driven computer control agent},
  author={Niu, Runliang and Li, Jindong and Wang, Shiqi and Fu, Yali and Hu, Xiyu and Leng, Xueyuan and Kong, He and Chang, Yi and Wang, Qi},
  journal={arXiv preprint arXiv:2402.07945},
  year={2024}
}

@article{zhang2024ufo,
  title={Ufo: A ui-focused agent for windows os interaction},
  author={Zhang, Chaoyun and Li, Liqun and He, Shilin and Zhang, Xu and Qiao, Bo and Qin, Si and Ma, Minghua and Kang, Yu and Lin, Qingwei and Rajmohan, Saravan and others},
  journal={arXiv preprint arXiv:2402.07939},
  year={2024}
}

@article{baechler2024screenai,
  title={Screenai: A vision-language model for ui and infographics understanding},
  author={Baechler, Gilles and Sunkara, Srinivas and Wang, Maria and Zubach, Fedir and Mansoor, Hassan and Etter, Vincent and C{\u{a}}rbune, Victor and Lin, Jason and Chen, Jindong and Sharma, Abhanshu},
  journal={arXiv preprint arXiv:2402.04615},
  year={2024}
}

@article{lu2024weblinx,
  title={Weblinx: Real-world website navigation with multi-turn dialogue},
  author={L{\`u}, Xing Han and Kasner, Zden{\v{e}}k and Reddy, Siva},
  journal={arXiv preprint arXiv:2402.05930},
  year={2024}
}

@inproceedings{xing2024AndroidArena,
  title={Understanding the weakness of large language model agents within a complex android environment},
  author={Xing, Mingzhe and Zhang, Rongkai and Xue, Hui and Chen, Qi and Yang, Fan and Xiao, Zhen},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6061--6072},
  year={2024}
}

@inproceedings{ma2024coco,
  title={Coco-agent: A comprehensive cognitive mllm agent for smartphone gui automation},
  author={Ma, Xinbei and Zhang, Zhuosheng and Zhao, Hai},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={9097--9110},
  year={2024}
}

@article{zhang2024aitz,
  title={Android in the zoo: Chain-of-action-thought for gui agents},
  author={Zhang, Jiwen and Wu, Jihao and Teng, Yihua and Liao, Minghui and Xu, Nuo and Xiao, Xiao and Wei, Zhongyu and Tang, Duyu},
  journal={arXiv preprint arXiv:2403.02713},
  year={2024}
}

@article{song2024trial,
  title={Trial and error: Exploration-based trajectory optimization for llm agents},
  author={Song, Yifan and Yin, Da and Yue, Xiang and Huang, Jie and Li, Sujian and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2403.02502},
  year={2024}
}

@article{you2024ferret,
  title={Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs},
  author={You, Keen and Zhang, Haotian and Schoop, Eldon and Weers, Floris and Swearngin, Amanda and Nichols, Jeffrey and Yang, Yinfei and Gan, Zhe},
  journal={arXiv preprint arXiv:2404.05719},
  year={2024}
}

@inproceedings{lai2024autowebglm,
  title={AutoWebGLM: A Large Language Model-based Web Navigating Agent},
  author={Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and others},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={5295--5306},
  year={2024}
}

@article{chen2024octopus,
  title={Octopus v2: On-device language model for super agent},
  author={Chen, Wei and Li, Zhiyuan},
  journal={arXiv preprint arXiv:2404.01744},
  year={2024}
}

@article{moniz2024realm,
  title={ReALM: Reference Resolution As Language Modeling},
  author={Moniz, Joel Ruben Antony and Krishnan, Soundarya and Ozyildirim, Melis and Saraf, Prathamesh and Ates, Halim Cagri and Zhang, Yuan and Yu, Hong and Rajshree, Nidhi},
  journal={arXiv preprint arXiv:2403.20329},
  year={2024}
}

@article{zhang2024llamatouch,
  title={LlamaTouch: A Faithful and Scalable Testbed for Mobile UI Automation Task Evaluation},
  author={Zhang, Li and Wang, Shihe and Jia, Xianqing and Zheng, Zhihan and Yan, Yunhe and Gao, Longxi and Li, Yuanchun and Xu, Mengwei},
  journal={arXiv preprint arXiv:2404.16054},
  year={2024}
}

@article{song2024mmac,
  title={MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot},
  author={Song, Zirui and Li, Yaohang and Fang, Meng and Chen, Zhenhao and Shi, Zecheng and Huang, Yuan},
  journal={arXiv preprint arXiv:2404.18074},
  year={2024}
}

@article{fereidouni2024search,
  title={Search Beyond Queries: Training Smaller Language Models for Web Interactions via Reinforcement Learning},
  author={Fereidouni, Moghis and Siddique, AB},
  journal={arXiv preprint arXiv:2404.10887},
  year={2024}
}

@inproceedings{taeb2024axnav,
  title={Axnav: Replaying accessibility tests from natural language},
  author={Taeb, Maryam and Swearngin, Amanda and Schoop, Eldon and Cheng, Ruijia and Jiang, Yue and Nichols, Jeffrey},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2024}
}

@article{wang2024mobileagentv2,
  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},
  author={Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},
  journal={arXiv preprint arXiv:2406.01014},
  year={2024}
}

@article{bai2024digirl,
  title={Digirl: Training in-the-wild device-control agents with autonomous reinforcement learning},
  author={Bai, Hao and Zhou, Yifei and Cemri, Mert and Pan, Jiayi and Suhr, Alane and Levine, Sergey and Kumar, Aviral},
  journal={arXiv preprint arXiv:2406.11896},
  year={2024}
}

@article{wu2024copilot,
  title={Os-copilot: Towards generalist computer agents with self-improvement},
  author={Wu, Zhiyong and Han, Chengcheng and Ding, Zichen and Weng, Zhenmin and Liu, Zhoumianze and Yao, Shunyu and Yu, Tao and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2402.07456},
  year={2024}
}

@article{wornow2024multimodal,
  title={Do Multimodal Foundation Models Understand Enterprise Workflows? A Benchmark for Business Process Management Tasks},
  author={Wornow, Michael and Narayan, Avanika and Viggiano, Ben and Khare, Ishan S and Verma, Tathagat and Thompson, Tibor and Hernandez, Miguel Angel Fuentes and Sundar, Sudharsan and Trujillo, Chloe and Chawla, Krrish and others},
  journal={arXiv preprint arXiv:2406.13264},
  year={2024}
}

@article{chen2024guicourse,
  title={GUICourse: From General Vision Language Models to Versatile GUI Agents},
  author={Chen, Wentong and Cui, Junbo and Hu, Jinyi and Qin, Yujia and Fang, Junjie and Zhao, Yue and Wang, Chongyi and Liu, Jun and Chen, Guirong and Huo, Yupeng and others},
  journal={arXiv preprint arXiv:2406.11317},
  year={2024}
}

@article{lu2024guiodyssey,
  title={GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices},
  author={Lu, Quanfeng and Shao, Wenqi and Liu, Zitao and Meng, Fanqing and Li, Boxuan and Chen, Botong and Huang, Siyuan and Zhang, Kaipeng and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2406.08451},
  year={2024}
}

@article{wang2024mobileagentbench,
  title={MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents},
  author={Wang, Luyuan and Deng, Yongyu and Zha, Yiwei and Mao, Guodong and Wang, Qinmin and Min, Tianchen and Chen, Wei and Chen, Shoufa},
  journal={arXiv preprint arXiv:2406.08184},
  year={2024}
}

@inproceedings{qian2024visualgrounding,
  title={Visual grounding for user interfaces},
  author={Qian, Yijun and Lu, Yujie and Hauptmann, Alexander G and Riva, Oriana},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)},
  pages={97--107},
  year={2024}
}

@inproceedings{dingenhancing,
  title={Enhancing Mobile" How-to" Queries with Automated Search Results Verification and Reranking},
  author={Ding, Lei and Zhang, Yi and Bheemanpally, Jeshwanth},
  booktitle={The Second Workshop on Generative Information Retrieval}
}

@article{zhang2024mobileexperts,
  title={MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices},
  author={Zhang, Jiayi and Zhao, Chuang and Zhao, Yihan and Yu, Zhaoyang and He, Ming and Fan, Jianping},
  journal={arXiv preprint arXiv:2407.03913},
  year={2024}
}

@inproceedings{tan2024cradle,
  title={Cradle: Empowering Foundation Agents towards General Computer Control},
  author={Tan, Weihao and Zhang, Wentao and Xu, Xinrun and Xia, Haochong and Ding, Ziluo and Li, Boyu and Zhou, Bohan and Yue, Junpeng and Jiang, Jiechuan and Li, Yewen and others},
  booktitle={NeurIPS 2024 Workshop on Open-World Agents}
}

@article{li2024androidcontrol,
  title={On the Effects of Data Scale on Computer Control Agents},
  author={Li, Wei and Bishop, William and Li, Alice and Rawles, Chris and Campbell-Ajala, Folawiyo and Tyamagundlu, Divya and Riva, Oriana},
  journal={arXiv preprint arXiv:2406.03679},
  year={2024}
}

@article{gou2024navigating,
  title={Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents},
  author={Gou, Boyu and Wang, Ruohan and Zheng, Boyuan and Xie, Yanan and Chang, Cheng and Shu, Yiheng and Sun, Huan and Su, Yu},
  journal={arXiv preprint arXiv:2410.05243},
  year={2024}
}

@article{wang2024distrl,
  title={DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents},
  author={Wang, Taiyi and Wu, Zhihao and Liu, Jianheng and Hao, Jianye and Wang, Jun and Shao, Kun},
  journal={arXiv preprint arXiv:2410.14803},
  year={2024}
}

@article{pawlowski2024tinyclick,
  title={TinyClick: Single-Turn Agent for Empowering GUI Automation},
  author={Pawlowski, Pawel and Zawistowski, Krystian and Lapacz, Wojciech and Skorupa, Marcin and Wiacek, Adam and Postansque, Sebastien and Hoscilowicz, Jakub},
  journal={arXiv preprint arXiv:2410.11871},
  year={2024}
}

@article{deng2024mobile,
  title={Mobile-bench: An evaluation benchmark for llm-based mobile agents},
  author={Deng, Shihan and Xu, Weikai and Sun, Hongda and Liu, Wei and Tan, Tao and Liu, Jianfeng and Li, Ang and Luan, Jian and Wang, Bin and Yan, Rui and others},
  journal={arXiv preprint arXiv:2407.00993},
  year={2024}
}

@article{chai2024amex,
  title={Amex: Android multi-annotation expo dataset for mobile gui agents},
  author={Chai, Yuxiang and Huang, Siyuan and Niu, Yazhe and Xiao, Han and Liu, Liang and Zhang, Dingyu and Gao, Peng and Ren, Shuai and Li, Hongsheng},
  journal={arXiv preprint arXiv:2407.17490},
  year={2024}
}

@article{abuelsaad2024agent,
  title={Agent-e: From autonomous web navigation to foundational design principles in agentic systems},
  author={Abuelsaad, Tamer and Akkil, Deepak and Dey, Prasenjit and Jagmohan, Ashish and Vempaty, Aditya and Kokku, Ravi},
  journal={arXiv preprint arXiv:2407.13032},
  year={2024}
}

@article{cao2024spider2,
  title={Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?},
  author={Cao, Ruisheng and Lei, Fangyu and Wu, Haoyuan and Chen, Jixuan and Fu, Yeqiao and Gao, Hongcheng and Xiong, Xinzhuang and Zhang, Hanchong and Mao, Yuchen and Hu, Wenjing and others},
  journal={arXiv preprint arXiv:2407.10956},
  year={2024}
}

@article{yang2024security,
  title={Security Matrix for Multimodal Agents on Mobile Devices: A Systematic and Proof of Concept Study},
  author={Yang, Yulong and Yang, Xinshan and Li, Shuaidong and Lin, Chenhao and Zhao, Zhengyu and Shen, Chao and Zhang, Tianwei},
  journal={arXiv preprint arXiv:2407.09295},
  year={2024}
}

@article{hu2024auitestagent,
  title={AUITestAgent: Automatic Requirements Oriented GUI Function Testing},
  author={Hu, Yongxiang and Wang, Xuan and Wang, Yingchuan and Zhang, Yu and Guo, Shiyu and Chen, Chaoyi and Wang, Xin and Zhou, Yangfan},
  journal={arXiv preprint arXiv:2407.09018},
  year={2024}
}

@article{nong2024mobileflow,
  title={MobileFlow: A Multimodal LLM For Mobile GUI Agent},
  author={Nong, Songqin and Zhu, Jiali and Wu, Rui and Jin, Jiongchao and Shan, Shuo and Huang, Xiutian and Xu, Wenhao},
  journal={arXiv preprint arXiv:2407.04346},
  year={2024}
}

@article{liu2024vision,
  title={Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model},
  author={Liu, Zhe and Li, Cheng and Chen, Chunyang and Wang, Junjie and Wu, Boyu and Wang, Yawen and Hu, Jun and Wang, Qing},
  journal={arXiv preprint arXiv:2407.03037},
  year={2024}
}


@article{ma2024caution,
  title={Caution for the environment: Multimodal agents are susceptible to environmental distractions},
  author={Ma, Xinbei and Wang, Yiting and Yao, Yao and Yuan, Tongxin and Zhang, Aston and Zhang, Zhuosheng and Zhao, Hai},
  journal={arXiv preprint arXiv:2408.02544},
  year={2024}
}

@article{lu2024omniparser,
  title={Omniparser for pure vision based gui agent},
  author={Lu, Yadong and Yang, Jianwei and Shen, Yelong and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2408.00203},
  year={2024}
}

@inproceedings{iong2024openwebagent,
  title={OpenWebAgent: An Open Toolkit to Enable Web Agents on Large Language Models},
  author={Iong, Iat Long and Liu, Xiao and Chen, Yuxuan and Lai, Hanyu and Yao, Shuntian and Shen, Pengbo and Yu, Hao and Dong, Yuxiao and Tang, Jie},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  pages={72--81},
  year={2024}
}

@article{zhang2024ui-hawk,
  title={UI-Hawk: Unleashing the screen stream understanding for gui agents},
  author={Zhang, Jiwen and Yu, Yaqi and Liao, Minghui and Li, Wentao and Wu, Jihao and Wei, Zhongyu},
  year={2024},
  publisher={Preprints}
}

@article{haque2024infering,
  title={Infering Alt-text For UI Icons With Large Language Models During App Development},
  author={Haque, Sabrina and Csallner, Christoph},
  journal={arXiv preprint arXiv:2409.18060},
  year={2024}
}

@article{zhang2024dynamic,
  title={Dynamic Planning for LLM-based Graphical User Interface Automation},
  author={Zhang, Shaoqing and Zhang, Zhuosheng and Chen, Kehai and Ma, Xinbe and Yang, Muyun and Zhao, Tiejun and Zhang, Min},
  journal={arXiv preprint arXiv:2410.00467},
  year={2024}
}

@article{userinterface,
  title={INTERFACE UNDERSTANDING ACROSS PLATFORMS},
  author={USER, MASTERING UNIVERSAL}
}

@article{lu2024turn,
  title={Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents},
  author={Lu, Junting and Zhang, Zhiyang and Yang, Fangkai and Zhang, Jue and Wang, Lu and Du, Chao and Lin, Qingwei and Rajmohan, Saravan and Zhang, Dongmei and Zhang, Qi},
  journal={arXiv preprint arXiv:2409.17140},
  year={2024}
}

@article{gao2024mobileviews,
  title={MobileViews: A Large-Scale Mobile GUI Dataset},
  author={Gao, Longxi and Zhang, Li and Wang, Shihe and Wang, Shangguang and Li, Yuanchun and Xu, Mengwei},
  journal={arXiv preprint arXiv:2409.14337},
  year={2024}
}

@article{huang2024promptrpa,
  title={PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts},
  author={Huang, Tian and Yu, Chun and Shi, Weinan and Peng, Zijian and Yang, David and Sun, Weiqi and Shi, Yuanchun},
  journal={arXiv preprint arXiv:2404.02475},
  year={2024}
}

@article{trivedi2024appworld,
  title={Appworld: A controllable world of apps and people for benchmarking interactive coding agents},
  author={Trivedi, Harsh and Khot, Tushar and Hartmann, Mareike and Manku, Ruskin and Dong, Vinty and Li, Edward and Gupta, Shashank and Sabharwal, Ashish and Balasubramanian, Niranjan},
  journal={arXiv preprint arXiv:2407.18901},
  year={2024}
}

@article{boisvert2024workarena++,
  title={Workarena++: Towards compositional planning and reasoning-based common knowledge work tasks},
  author={Boisvert, L{\'e}o and Thakkar, Megh and Gasse, Maxime and Caccia, Massimo and Chezelles, De and Le Sellier, Thibault and Cappart, Quentin and Chapados, Nicolas and Lacoste, Alexandre and Drouin, Alexandre},
  journal={arXiv preprint arXiv:2407.05291},
  year={2024}
}

@article{xu2024crab,
  title={Crab: Cross-environment agent benchmark for multimodal language model agents},
  author={Xu, Tianqi and Chen, Linyao and Wu, Dai-Jie and Chen, Yanjun and Zhang, Zecheng and Yao, Xiang and Xie, Zhiqiang and Chen, Yongchao and Liu, Shilong and Qian, Bochen and others},
  journal={arXiv preprint arXiv:2407.01511},
  year={2024}
}

@article{pan2024webcanvas,
  title={WebCanvas: Benchmarking Web Agents in Online Environments},
  author={Pan, Yichen and Kong, Dehan and Zhou, Sida and Cui, Cheng and Leng, Yifei and Jiang, Bing and Liu, Hangyu and Shang, Yanyi and Zhou, Shuyan and Wu, Tongshuang and others},
  journal={arXiv preprint arXiv:2406.12373},
  year={2024}
}

@article{rawles2024androidworld,
  title={AndroidWorld: A dynamic benchmarking environment for autonomous agents},
  author={Rawles, Christopher and Clinckemaillie, Sarah and Chang, Yifan and Waltz, Jonathan and Lau, Gabrielle and Fair, Marybeth and Li, Alice and Bishop, William and Li, Wei and Campbell-Ajala, Folawiyo and others},
  journal={arXiv preprint arXiv:2405.14573},
  year={2024}
}

@article{drouin2024workarena,
  title={WorkArena: How Capable are Web Agents at Solving Common Knowledge Work Tasks?},
  author={Drouin, Alexandre and Gasse, Maxime and Caccia, Massimo and Laradji, Issam H and Del Verme, Manuel and Marty, Tom and Boisvert, L{\'e}o and Thakkar, Megh and Cappart, Quentin and Vazquez, David and others},
  journal={arXiv preprint arXiv:2403.07718},
  year={2024}
}

@article{guo2023pptc,
  title={Pptc benchmark: Evaluating large language models for powerpoint task completion},
  author={Guo, Yiduo and Zhang, Zekai and Liang, Yaobo and Zhao, Dongyan and Duan, Nan},
  journal={arXiv preprint arXiv:2311.01767},
  year={2023}
}

@inproceedings{deng2024large,
  title={Large Language Model Powered Agents in the Web},
  author={Deng, Yang and Zhang, An and Lin, Yankai and Chen, Xu and Wen, Ji-Rong and Chua, Tat-Seng},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1242--1245},
  year={2024}
}

@article{pointedlayout,
  title={Layout-aware GUI Screen Reading with Tree-of-Lens Grounding},
  author={Pointed, Read Anywhere}
}

@article{jing2024dsbench,
  title={DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?},
  author={Jing, Liqiang and Huang, Zhehui and Wang, Xiaoyang and Yao, Wenlin and Yu, Wenhao and Ma, Kaixin and Zhang, Hongming and Du, Xinya and Yu, Dong},
  journal={arXiv preprint arXiv:2409.07703},
  year={2024}
}

@article{kapoor2024omniact,
  title={OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web},
  author={Kapoor, Raghav and Butala, Yash Parag and Russak, Melisa and Koh, Jing Yu and Kamble, Kiran and Alshikh, Waseem and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2402.17553},
  year={2024}
}

@article{liu2024visualwebbench,
  title={VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?},
  author={Liu, Junpeng and Song, Yifan and Lin, Bill Yuchen and Lam, Wai and Neubig, Graham and Li, Yuanzhi and Yue, Xiang},
  journal={arXiv preprint arXiv:2404.05955},
  year={2024}
}

@article{ma2023laser,
  title={Laser: Llm agent with state-space exploration for web navigation},
  author={Ma, Kaixin and Zhang, Hongming and Wang, Hongwei and Pan, Xiaoman and Yu, Wenhao and Yu, Dong},
  journal={arXiv preprint arXiv:2309.08172},
  year={2023}
}

@article{liu2023alltogether,
  title={AllTogether: Investigating the Efficacy of Spliced Prompt for Web Navigation using Large Language Models},
  author={Liu, Jiarun and Hu, Wentao and Zhang, Chunhong},
  journal={arXiv preprint arXiv:2310.18331},
  year={2023}
}

@article{qinghong2024videogui,
  title={VideoGUI: A Benchmark for GUI Automation from Instructional Videos},
  author={Qinghong Lin, Kevin and Li, Linjie and Gao, Difei and WU, Qinchen and Yan, Mingyi and Yang, Zhengyuan and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv e-prints},
  pages={arXiv--2406},
  year={2024}
}

@article{ettifouri2024visual,
  title={Visual grounding for desktop graphical user interfaces Tassnim Dardouri, Laura Minkova, Jessica L{\'o}pez Espejel, Walid Dahhane},
  author={Ettifouri, El Hassane},
  journal={arXiv preprint arXiv:2407.01558},
  year={2024}
}


% -----------------------TPAMI Added-----------------------
% ---------------- introduction --------------------------
@misc{bavishi2023fuyu,
  title={Fuyu-8B: A multimodal architecture for AI agents},
  author={Bavishi, Rohan and Elsen, Erich and Hawthorne, Curtis and Nye, Maxwell and Odena, Augustus and Somani, Arushi and Ta{\c{s}}{\i}rlar, Sa{\u{g}}nak},
  year={2023}
}

@inproceedings{furuta2024exposing,
  title={Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web},
  author={Furuta, Hiroki and Matsuo, Yutaka and Faust, Aleksandra and Gur, Izzeddin},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024}
}

@inproceedings{wu2021screen,
  title={Screen parsing: Towards reverse engineering of ui models from screenshots},
  author={Wu, Jason and Zhang, Xiaoyi and Nichols, Jeff and Bigham, Jeffrey P},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={470--483},
  year={2021}
}

% -------- UI Information Perception (section 3.1.1)--------------
%% ----------------------- UI tree -----------------------
@article{guan2023intelligent,
  title={Intelligent virtual assistants with llm-based process automation},
  author={Guan, Yanchu and Wang, Dong and Chu, Zhixuan and Wang, Shiyu and Ni, Feiyue and Song, Ruihua and Li, Longfei and Gu, Jinjie and Zhuang, Chenyi},
  journal={arXiv preprint arXiv:2312.06677},
  year={2023}
}
%% --不确定是否加入这篇-------------------
@misc{fan2024readpointedlayoutawaregui,
      title={Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding}, 
      author={Yue Fan and Lei Ding and Ching-Chen Kuo and Shan Jiang and Yang Zhao and Xinze Guan and Jie Yang and Yi Zhang and Xin Eric Wang},
      year={2024},
      eprint={2406.19263},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19263}, 
}
%% ---------------------- screenshots ----------------------
@article{he2024webvoyager,
  title={WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models},
  author={He, Hongliang and Yao, Wenlin and Ma, Kaixin and Yu, Wenhao and Dai, Yong and Zhang, Hongming and Lan, Zhenzhong and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13919},
  year={2024}
}
@article{tang2024steward,
  title={Steward: Natural language web automation},
  author={Tang, Brian and Shin, Kang G},
  journal={arXiv preprint arXiv:2409.15441},
  year={2024}
}
@inproceedings{song2024visiontasker,
  title={Visiontasker: Mobile task automation using vision based ui understanding and llm task planning},
  author={Song, Yunpeng and Bian, Yiheng and Tang, Yongtao and Ma, Guiyu and Cai, Zhongmin},
  booktitle={Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--17},
  year={2024}
}

@article{wu2024mobilevlm,
  title={Mobilevlm: A vision-language model for better intra-and inter-ui understanding},
  author={Wu, Qinzhuo and Xu, Weikai and Liu, Wei and Tan, Tao and Liu, Jianfeng and Li, Ang and Luan, Jian and Wang, Bin and Shang, Shuo},
  journal={arXiv preprint arXiv:2409.14818},
  year={2024}
}

%% ----------------------- Icon & OCR enhancements ------------------------
@article{bonatti2024windows,
  title={Windows agent arena: Evaluating multi-modal os agents at scale},
  author={Bonatti, Rogerio and Zhao, Dan and Bonacci, Francesco and Dupont, Dillon and Abdali, Sara and Li, Yinheng and Lu, Yadong and Wagle, Justin and Koishida, Kazuhito and Bucker, Arthur and others},
  journal={arXiv preprint arXiv:2409.08264},
  year={2024}
}

% --------------- Brain in Phone GUI Agents (section 3.2) -----------
%% -------- planning, reflection (section 3.2)-------------
@article{li2023zero,
  title={A Zero-Shot Language Agent for Computer Control with Structured Reflection},
  author={Li, Tao and Li, Gang and Deng, Zhiwei and Wang, Bryan and Li, Yang},
  journal={arXiv preprint arXiv:2310.08740},
  year={2023}
}
% 直接加入开头了
@article{ge2023llm,
  title={LLM as OS, agents as apps: Envisioning AIOS, agents and the AIOS-agent ecosystem},
  author={Ge, Yingqiang and Ren, Yujie and Hua, Wenyue and Xu, Shuyuan and Tan, Juntao and Zhang, Yongfeng},
  journal={arXiv e-prints},
  pages={arXiv--2312},
  year={2023}
}

@article{mei2024aios,
  title={AIOS: LLM agent operating system},
  author={Mei, Kai and Li, Zelong and Xu, Shuyuan and Ye, Ruosong and Ge, Yingqiang and Zhang, Yongfeng},
  journal={arXiv e-prints, pp. arXiv--2403},
  year={2024}
}
%% 自动化ui评估
@article{pan2024autonomous,
  title={Autonomous evaluation and refinement of digital agents},
  author={Pan, Jiayi and Zhang, Yichi and Tomlin, Nicholas and Zhou, Yifei and Levine, Sergey and Suhr, Alane},
  journal={arXiv preprint arXiv:2404.06474},
  year={2024}
}

@inproceedings{duan2024uicrit,
  title={UICrit: Enhancing Automated Design Evaluation with a UI Critique Dataset},
  author={Duan, Peitong and Cheng, Chin-Yi and Li, Gang and Hartmann, Bjoern and Li, Yang},
  booktitle={Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--17},
  year={2024}
}

%% ------------------- reason ------------------------
@article{bishop2024latent,
  title={Latent State Estimation Helps UI Agents to Reason},
  author={Bishop, William E and Li, Alice and Rawles, Christopher and Riva, Oriana},
  journal={arXiv preprint arXiv:2405.11120},
  year={2024}
}

@article{koh2024tree,
  title={Tree search for language model agents},
  author={Koh, Jing Yu and McAleer, Stephen and Fried, Daniel and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2407.01476},
  year={2024}
}

%% ------------------ Storage ---------------------------
@article{deng2024multi,
  title={On the Multi-turn Instruction Following for Conversational Web Agents},
  author={Deng, Yang and Zhang, Xuan and Zhang, Wenxuan and Yuan, Yifei and Ng, See-Kiong and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2402.15057},
  year={2024}
}

@article{li2024appagentv2,
  title={Appagent v2: Advanced agent for flexible mobile interactions},
  author={Li, Yanda and Zhang, Chi and Yang, Wanqi and Fu, Bin and Cheng, Pei and Chen, Xin and Chen, Ling and Wei, Yunchao},
  journal={arXiv preprint arXiv:2408.11824},
  year={2024}
}

% ---------- Multi-Agent Framework (section 3.4) ----------------
%% -------------------- intro -----------------------
@article{talebirad2023multi,
  title={Multi-agent collaboration: Harnessing the power of intelligent llm agents},
  author={Talebirad, Yashar and Nadiri, Amirhossein},
  journal={arXiv preprint arXiv:2306.03314},
  year={2023}
}

@article{wu2023autogen,
  title={Autogen: Enabling next-gen llm applications via multi-agent conversation framework},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@inproceedings{chen2023agentverse,
  title={Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Chan, Chi-Min and Yu, Heyang and Lu, Yaxi and Hung, Yi-Hsin and Qian, Chen and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{li2023theory,
  title={Theory of mind for multi-agent collaboration via large language models},
  author={Li, Huao and Chong, Yu Quan and Stepputtis, Simon and Campbell, Joseph and Hughes, Dana and Lewis, Michael and Sycara, Katia},
  journal={arXiv preprint arXiv:2310.10701},
  year={2023}
}

@inproceedings{liu2024dynamic,
  title={A dynamic LLM-powered agent network for task-oriented agent collaboration},
  author={Liu, Zijun and Zhang, Yanzhe and Li, Peng and Liu, Yang and Yang, Diyi},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@article{tran2025multi,
  title={Multi-Agent Collaboration Mechanisms: A Survey of LLMs},
  author={Tran, Khanh-Tung and Dao, Dung and Nguyen, Minh-Duong and Pham, Quoc-Viet and O'Sullivan, Barry and Nguyen, Hoang D},
  journal={arXiv preprint arXiv:2501.06322},
  year={2025}
}

%% ----------------- Framework -----------------------
@article{gong2023mindagent,
  title={Mindagent: Emergent gaming interaction},
  author={Gong, Ran and Huang, Qiuyuan and Ma, Xiaojian and Vo, Hoi and Durante, Zane and Noda, Yusuke and Zheng, Zilong and Zhu, Song-Chun and Terzopoulos, Demetri and Fei-Fei, Li and others},
  journal={arXiv preprint arXiv:2309.09971},
  year={2023}
}

@article{zhang2024webpilot,
  title={Webpilot: A versatile and autonomous multi-agent system for web task execution with strategic exploration},
  author={Zhang, Yao and Ma, Zijian and Ma, Yunpu and Han, Zhen and Wu, Yu and Tresp, Volker},
  journal={arXiv preprint arXiv:2408.15978},
  year={2024}
}

@inproceedings{yin2024agent,
  title={Agent lumos: Unified and modular training for open-source language agents},
  author={Yin, Da and Brahman, Faeze and Ravichander, Abhilasha and Chandu, Khyathi and Chang, Kai-Wei and Choi, Yejin and Lin, Bill Yuchen},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12380--12403},
  year={2024}
}

@article{wang2025mobile,
  title={Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks},
  author={Wang, Zhenhailong and Xu, Haiyang and Wang, Junyang and Zhang, Xi and Yan, Ming and Zhang, Ji and Huang, Fei and Ji, Heng},
  journal={arXiv preprint arXiv:2501.11733},
  year={2025}
}

@article{zhang2024ask,
  title={Ask-before-Plan: Proactive Language Agents for Real-World Planning},
  author={Zhang, Xuan and Deng, Yang and Ren, Zifeng and Ng, See-Kiong and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2406.12639},
  year={2024}
}

% ----------------- plan-then-act ---------------------
@article{wang2024ponder,
  title={Ponder \& Press: Advancing Visual GUI Agent towards General Computer Control},
  author={Wang, Yiqin and Zhang, Haoji and Tian, Jingqi and Tang, Yansong},
  journal={arXiv preprint arXiv:2412.01268},
  year={2024}
}

% ----------COT (section 4.1: Prompt Engineering)----------------------
@article{zhang2023igniting,
  title={Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents},
  author={Zhang, Zhuosheng and Yao, Yao and Zhang, Aston and Tang, Xiangru and Ma, Xinbei and He, Zhiwei and Wang, Yiming and Gerstein, Mark and Wang, Rui and Liu, Gongshen and others},
  journal={arXiv preprint arXiv:2311.11797},
  year={2023}
}

@article{wu2024gui,
  title={GUI Action Narrator: Where and When Did That Action Take Place?},
  author={Wu, Qinchen and Gao, Difei and Lin, Kevin Qinghong and Wu, Zhuoyu and Guo, Xiangwu and Li, Peiran and Zhang, Weichen and Wang, Hengxu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2406.13719},
  year={2024}
}

% ---------- Multimodal Prompt (section 4.1: Prompt Engineering) -------
@inproceedings{zheng2023synapse,
  title={Synapse: Trajectory-as-exemplar prompting with memory for computer control},
  author={Zheng, Longtao and Wang, Rundong and Wang, Xinrun and An, Bo},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{koh2024visualwebarena,
  title={Visualwebarena: Evaluating multimodal agents on realistic visual web tasks},
  author={Koh, Jing Yu and Lo, Robert and Jang, Lawrence and Duvvur, Vikram and Lim, Ming Chong and Huang, Po-Yu and Neubig, Graham and Zhou, Shuyan and Salakhutdinov, Ruslan and Fried, Daniel},
  journal={arXiv preprint arXiv:2401.13649},
  year={2024}
}
% ---------- General-Purpose (section 4.2: training-based)--------------
@article{lin2024showui,
  title={Showui: One vision-language-action model for gui visual agent},
  author={Lin, Kevin Qinghong and Li, Linjie and Gao, Difei and Yang, Zhengyuan and Wu, Shiwei and Bai, Zechen and Lei, Weixian and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2411.17465},
  year={2024}
}
@article{xu2024aguvis,
  title={Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction},
  author={Xu, Yiheng and Wang, Zekun and Wang, Junli and Lu, Dunjie and Xie, Tianbao and Saha, Amrita and Sahoo, Doyen and Yu, Tao and Xiong, Caiming},
  journal={arXiv preprint arXiv:2412.04454},
  year={2024}
}

@article{qin2025ui,
  title={UI-TARS: Pioneering Automated GUI Interaction with Native Agents},
  author={Qin, Yujia and Ye, Yining and Fang, Junjie and Wang, Haoming and Liang, Shihao and Tian, Shizuo and Zhang, Junda and Li, Jiahao and Li, Yunxin and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2501.12326},
  year={2025}
}

% ----------UI grounding (section 4.2: training-based)--------------
%% 2022年文章，引用次数仅为8，有待考究，当时并没有llm，只能说它提出多轮交互来纠正细化用户指令
@article{li2022mug,
  title={Mug: Interactive multimodal grounding on user interfaces},
  author={Li, Tao and Li, Gang and Zheng, Jingjie and Wang, Purple and Li, Yang},
  journal={arXiv preprint arXiv:2209.15099},
  year={2022}
}

@article{yang2024aria,
  title={Aria-UI: Visual Grounding for GUI Instructions},
  author={Yang, Yuhao and Wang, Yue and Li, Dongxu and Luo, Ziyang and Chen, Bei and Huang, Chao and Li, Junnan},
  journal={arXiv preprint arXiv:2412.16256},
  year={2024}
}

@article{wu2024atlas,
  title={Os-atlas: A foundation action model for generalist gui agents},
  author={Wu, Zhiyong and Wu, Zhenyu and Xu, Fangzhi and Wang, Yian and Sun, Qiushi and Jia, Chengyou and Cheng, Kanzhi and Ding, Zichen and Chen, Liheng and Liang, Paul Pu and others},
  journal={arXiv preprint arXiv:2410.23218},
  year={2024}
}

@article{fan2025gui,
  title={GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration},
  author={Fan, Yue and Zhao, Handong and Zhang, Ruiyi and Shen, Yu and Wang, Xin Eric and Wu, Gang},
  journal={arXiv preprint arXiv:2501.13896},
  year={2025}
}

@article{liu2025infiguiagent,
  title={InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection},
  author={Liu, Yuhang and Li, Pengxiang and Wei, Zishu and Xie, Congkai and Hu, Xueyu and Xu, Xinchen and Zhang, Shengyu and Han, Xiaotian and Yang, Hongxia and Wu, Fei},
  journal={arXiv preprint arXiv:2501.04575},
  year={2025}
}

%% ------------ tuning-free ----------------------
@article{xu2024attention,
  title={Attention-driven GUI Grounding: Leveraging Pretrained Multimodal Large Language Models without Fine-Tuning},
  author={Xu, Hai-Ming and Chen, Qi and Wang, Lei and Liu, Lingqiao},
  journal={arXiv preprint arXiv:2412.10840},
  year={2024}
}

% ---------- UI referring (section 4.2: training-based)--------------
@misc{li2024ferretui2masteringuniversal,
      title={Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms}, 
      author={Zhangheng Li and Keen You and Haotian Zhang and Di Feng and Harsh Agrawal and Xiujun Li and Mohana Prasad Sathya Moorthy and Jeff Nichols and Yinfei Yang and Zhe Gan},
      year={2024},
      eprint={2410.18967},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.18967}, 
}

@article{burns2024tell,
  title={Tell Me What's Next: Textual Foresight for Generic UI Representations},
  author={Burns, Andrea and Saenko, Kate and Plummer, Bryan A},
  journal={arXiv preprint arXiv:2406.07822},
  year={2024}
}

% -------- Supervised Fine-Tuning ----------------------------
@article{yuan2025agent,
  title={Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training},
  author={Yuan, Siyu and Chen, Zehui and Xi, Zhiheng and Ye, Junjie and Du, Zhengyin and Chen, Jiecao},
  journal={arXiv preprint arXiv:2501.11425},
  year={2025}
}

@article{ding2024mobileagentsop,
  title={MobileAgent: enhancing mobile control via human-machine interaction and SOP integration},
  author={Ding, Tinghe},
  journal={arXiv preprint arXiv:2401.04124},
  year={2024}
}

% -------- RL (section 4.2.3: Reinforcement Learning) -----------
@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{gao2023assistgui,
  title={Assistgui: Task-oriented desktop graphical user interface automation},
  author={Gao, Difei and Ji, Lei and Bai, Zechen and Ouyang, Mingyu and Li, Peiran and Mao, Dongxing and Wu, Qinchen and Zhang, Weichen and Wang, Peiyi and Guo, Xiangwu and others},
  journal={arXiv preprint arXiv:2312.13108},
  year={2023}
}

@inproceedings{Fereidouni_2024,
   title={Grounded Language Agent for Product Search via Intelligent Web Interactions},
   url={http://dx.doi.org/10.18653/v1/2024.customnlp4u-1.7},
   DOI={10.18653/v1/2024.customnlp4u-1.7},
   booktitle={Proceedings of the 1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual (CustomNLP4U)},
   publisher={Association for Computational Linguistics},
   author={Fereidouni, Moghis and Mosharrof, Adib and Siddique, A.b.},
   year={2024},
   pages={63–75} 
}
%% ----------- mobile -------------------
@article{wu2025reachagent,
  title={ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation},
  author={Wu, Qinzhuo and Liu, Wei and Luan, Jian and Wang, Bin},
  journal={arXiv preprint arXiv:2502.02955},
  year={2025}
}

% ----------------- dataset -----------------------
@inproceedings{deka2017rico,
  title={Rico: A mobile app dataset for building data-driven design applications},
  author={Deka, Biplab and Huang, Zifeng and Franzen, Chad and Hibschman, Joshua and Afergan, Daniel and Li, Yang and Nichols, Jeffrey and Kumar, Ranjitha},
  booktitle={Proceedings of the 30th annual ACM symposium on user interface software and technology},
  pages={845--854},
  year={2017}
}

@article{sunkara2022towards,
  title={Towards better semantic understanding of mobile interfaces},
  author={Sunkara, Srinivas and Wang, Maria and Liu, Lijuan and Baechler, Gilles and Hsiao, Yu-Chung and Sharma, Abhanshu and Stout, James and others},
  journal={arXiv preprint arXiv:2210.02663},
  year={2022}
}

@article{berkovitch2024identifying,
  title={Identifying User Goals from UI Trajectories},
  author={Berkovitch, Omri and Caduri, Sapir and Kahlon, Noam and Efros, Anatoly and Caciularu, Avi and Dagan, Ido},
  journal={arXiv preprint arXiv:2406.14314},
  year={2024}
}

@inproceedings{peng2024dreamstruct,
  title={Dreamstruct: Understanding slides and user interfaces via synthetic data generation},
  author={Peng, Yi-Hao and Huq, Faria and Jiang, Yue and Wu, Jason and Li, Xin Yue and Bigham, Jeffrey P and Pavel, Amy},
  booktitle={European Conference on Computer Vision},
  pages={466--485},
  year={2024},
  organization={Springer}
}

@article{sun2024genesis,
  title={OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis},
  author={Sun, Qiushi and Cheng, Kanzhi and Ding, Zichen and Jin, Chuanyang and Wang, Yian and Xu, Fangzhi and Wu, Zhenyu and Jia, Chengyou and Chen, Liheng and Liu, Zhoumianze and others},
  journal={arXiv preprint arXiv:2412.19723},
  year={2024}
}

@article{su2025learn,
  title={Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments},
  author={Su, Hongjin and Sun, Ruoxi and Yoon, Jinsung and Yin, Pengcheng and Yu, Tao and Ar{\i}k, Sercan {\"O}},
  journal={arXiv preprint arXiv:2501.10893},
  year={2025}
}

@article{wang2025fedmobileagent,
  title={FedMobileAgent: Training Mobile Agents Using Decentralized Self-Sourced Data from Diverse Users},
  author={Wang, Wenhao and Yu, Zijie and Liu, William and Ye, Rui and Jin, Tian and Chen, Siheng and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2502.02982},
  year={2025}
}

@article{chen2024gui,
  title={GUI-WORLD: A Dataset for GUI-oriented Multimodal LLM-based Agents},
  author={Chen, Dongping and Huang, Yue and Wu, Siyuan and Tang, Jingyu and Chen, Liuyi and Bai, Yilin and He, Zhigang and Wang, Chenlong and Zhou, Huichi and Li, Yiqiang and others},
  journal={arXiv preprint arXiv:2406.10819},
  year={2024}
}

@article{gao2024mobileviews,
  title={Mobileviews: A large-scale mobile gui dataset},
  author={Gao, Longxi and Zhang, Li and Wang, Shihe and Wang, Shangguang and Li, Yuanchun and Xu, Mengwei},
  journal={arXiv preprint arXiv:2409.14337},
  year={2024}
}

% ----------------- benchmark ----------------------
@article{chai2025a3,
  title={A3: Android Agent Arena for Mobile GUI Agents},
  author={Chai, Yuxiang and Li, Hanhao and Zhang, Jiayu and Liu, Liang and Wang, Guozhi and Ren, Shuai and Huang, Siyuan and Li, Hongsheng},
  journal={arXiv preprint arXiv:2501.01149},
  year={2025}
}

@article{zheng2024agentstudio,
  title={Agentstudio: A toolkit for building general virtual agents},
  author={Zheng, Longtao and Huang, Zhiyuan and Xue, Zhenghai and Wang, Xinrun and An, Bo and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2403.17918},
  year={2024}
}

@article{liu2024visualagentbench,
  title={Visualagentbench: Towards large multimodal models as visual foundation agents},
  author={Liu, Xiao and Zhang, Tianjie and Gu, Yu and Iong, Iat Long and Xu, Yifan and Song, Xixuan and Zhang, Shudan and Lai, Hanyu and Liu, Xinyi and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2408.06327},
  year={2024}
}

% ----------------- challenges --------------------
@article{yang2024watch,
  title={Watch out for your agents! investigating backdoor threats to llm-based agents},
  author={Yang, Wenkai and Bi, Xiaohan and Lin, Yankai and Chen, Sishuo and Zhou, Jie and Sun, Xu},
  journal={arXiv preprint arXiv:2402.11208},
  year={2024}
}

@article{wang2024badagent,
  title={BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents},
  author={Wang, Yifei and Xue, Dizhan and Zhang, Shengjie and Qian, Shengsheng},
  journal={arXiv preprint arXiv:2406.03007},
  year={2024}
}

@article{wu2024adversarial,
  title={Adversarial Attacks on Multimodal Agents},
  author={Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi},
  journal={arXiv preprint arXiv:2406.12814},
  year={2024}
}

@article{citation-111,
  title={What’s important here?: Opportunities and Challenges of LLM in retrieving information from Web Interface},
  author={Huq, Faria and Bigham, Jeffrey P and Martelaro, Nikolas},
  journal={R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models}
}

%% --------------- Lightweight ------------------------
@article{wen2024autodroidv2,
  title={AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation},
  author={Wen, Hao and Tian, Shizuo and Pavlov, Borislav and Du, Wenjie and Li, Yixuan and Chang, Ge and Zhao, Shanhui and Liu, Jiacheng and Liu, Yunxin and Zhang, Ya-Qin and others},
  journal={arXiv preprint arXiv:2412.18116},
  year={2024}
}


%% -------------- dataset -------------------
@article{lin2024videogui,
  title={VideoGUI: A Benchmark for GUI Automation from Instructional Videos},
  author={Lin, Kevin Qinghong and Li, Linjie and Gao, Difei and Wu, Qinchen and Yan, Mingyi and Yang, Zhengyuan and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2406.10227},
  year={2024}
}

%% ------------- Interaction and Personalization -----------
@inproceedings{li2024uinav,
  title={UINav: A practical approach to train On-Device automation agents},
  author={Li, Wei and Hsu, Fu-Lin and Bishop, William and Campbell-Ajala, Folawiyo and Lin, Max and Riva, Oriana},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)},
  pages={36--51},
  year={2024}
}

@article{verma2024adaptagent,
  title={Adaptagent: Adapting multimodal web agents with few-shot learning from human demonstrations},
  author={Verma, Gaurav and Kaur, Rachneet and Srishankar, Nishan and Zeng, Zhen and Balch, Tucker and Veloso, Manuela},
  journal={arXiv preprint arXiv:2411.13451},
  year={2024}
}
@article{wang2024comprehensive,
  title={A comprehensive survey of small language models in the era of large language models: Techniques, enhancements, applications, collaboration with llms, and trustworthiness},
  author={Wang, Fali and Zhang, Zhiwei and Zhang, Xianren and Wu, Zongyu and Mo, Tzuhao and Lu, Qiuhao and Wang, Wanjing and Li, Rui and Xu, Junjie and Tang, Xianfeng and others},
  journal={arXiv preprint arXiv:2411.03350},
  year={2024}
}
